# app.py â€” Craigslist Used Car Price â€¢ Showcase (preloaded BaggingRegressor pipeline)
from __future__ import annotations
import os
import numpy as np
import pandas as pd
import streamlit as st
import joblib
import altair as alt
import plotly.express as px

st.set_page_config(page_title="Craigslist Car Price â€¢ Showcase", page_icon="ðŸš—", layout="wide")

# ====== IMPORTANT: helper used inside the saved Pipeline (needed for unpickling)
# It MUST match the function name & logic used when you saved the joblib in Colab.
def transform_numeric_whole_df(X):
    X = X.copy()
    X['year'] = X['year'].astype(float) - 1900.0
    X['odometer'] = (X['odometer'].astype(float) // 5000).astype(float)
    return X

# -------- Training schema (columns the pipeline was trained with)
TRAIN_CAT_COLS = [
    'manufacturer','condition','cylinders','fuel','transmission','drive','type','paint_color','state'
]
TRAIN_NUM_COLS = ['year','odometer']
TRAIN_INPUT_COLS = TRAIN_CAT_COLS + TRAIN_NUM_COLS

# -------- Paths (already created in Step 2)
MODEL_PATH = "models/final_pipeline.joblib"
EDA_SAMPLE_PATH = "data/eda_sample.parquet"

# -------- Load assets
@st.cache_resource(show_spinner=False)
def load_model():
    if not os.path.exists(MODEL_PATH):
        return None
    return joblib.load(MODEL_PATH)  # single sklearn Pipeline (preprocessing + BaggingRegressor)

@st.cache_data(show_spinner=False)
def load_eda_sample():
    if os.path.exists(EDA_SAMPLE_PATH):
        df = pd.read_parquet(EDA_SAMPLE_PATH)
        # ensure consistent dtypes
        for c in TRAIN_CAT_COLS:
            if c in df.columns:
                df[c] = df[c].astype(str).str.strip().str.lower()
        for c in TRAIN_NUM_COLS:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors='coerce')
        # State code helper if provided by full EDA export
        if 'state_code' in df.columns:
            df['state_code'] = df['state_code'].astype(str).str.upper()
        return df
    # Friendly fallback so evaluators can still open the app
    rng = np.random.default_rng(7); n=8000
    return pd.DataFrame({
        'price': rng.integers(1500, 40000, n),
        'year': rng.integers(1998, 2024, n),
        'manufacturer': rng.choice(['toyota','honda','ford','chevrolet','bmw','mercedes-benz','nissan','hyundai'], n),
        'condition': rng.choice(['excellent','good','fair','like new','salvage'], n),
        'cylinders': rng.choice(['3 cylinders','4 cylinders','6 cylinders','8 cylinders'], n),
        'fuel': rng.choice(['gas','diesel','hybrid','electric'], n),
        'odometer': rng.integers(5_000, 230_000, n),
        'transmission': rng.choice(['automatic','manual'], n),
        'drive': rng.choice(['fwd','rwd','4wd'], n),
        'type': rng.choice(['sedan','SUV','pickup','hatchback','wagon'], n),
        'paint_color': rng.choice(['white','black','silver','gray','blue','red'], n),
        'state': rng.choice(['ca','tx','ny','fl','wa','il','pa','oh','mi','ga'], n),
        'state_code': rng.choice(['CA','TX','NY','FL','WA','IL','PA','OH','MI','GA'], n),
    })

# Aggregates loader (optional parquet files for instant visuals)
@st.cache_data(show_spinner=False)
def load_aggregates():
    aggs = {}
    try:
        if os.path.exists('data/state_price.parquet'):
            aggs['state_price'] = pd.read_parquet('data/state_price.parquet')
            if 'state_code' in aggs['state_price'].columns:
                aggs['state_price']['state_code'] = aggs['state_price']['state_code'].astype(str).str.upper()
        if os.path.exists('data/year_price.parquet'):
            aggs['year_price'] = pd.read_parquet('data/year_price.parquet')
        if os.path.exists('data/mfr_type_freq.parquet'):
            aggs['mfr_type_freq'] = pd.read_parquet('data/mfr_type_freq.parquet')
        if os.path.exists('data/odo_price_grid.parquet'):
            aggs['odo_price_grid'] = pd.read_parquet('data/odo_price_grid.parquet')
    except Exception as e:
        st.warning(f"Could not load aggregate files: {e}")
    return aggs

# -------- Small helpers

def sanitize_inputs(row: pd.DataFrame) -> pd.DataFrame:
    """Ensure the predict row has exactly the training columns with correct dtypes."""
    r = row.copy()
    # Lowercase/canonicalize categoricals
    for c in TRAIN_CAT_COLS:
        if c in r.columns:
            r[c] = r[c].astype(str).str.strip().str.lower()
        else:
            r[c] = ''
    # Numerics to numeric
    for c in TRAIN_NUM_COLS:
        if c in r.columns:
            r[c] = pd.to_numeric(r[c], errors='coerce')
        else:
            r[c] = np.nan
    # Keep only training columns, in order
    r = r[TRAIN_INPUT_COLS]
    return r

model = load_model()
df = load_eda_sample()
aggs = load_aggregates()

# -------- Minimal brand colors / polish
st.markdown(
    """
    <style>
    :root {--brand: #1f6feb; --muted: #6b7280}
    .smallcap {color: var(--muted); font-size: 0.9rem}
    </style>
    """,
    unsafe_allow_html=True,
)

# -------- Header & KPIs
st.markdown("# ðŸš— Craigslist Car Price â€” <span class='smallcap'>Showcase</span>", unsafe_allow_html=True)
st.caption("Preloaded BaggingRegressor pipeline â€¢ Interactive EDA â€¢ No uploads required")

c1, c2, c3, c4 = st.columns(4)
c1.metric("Rows", f"{len(df):,}")
c2.metric("Median Price", f"${df['price'].median():,.0f}" if 'price' in df else "â€”")
c3.metric("Manufacturers", df['manufacturer'].nunique() if 'manufacturer' in df else 0)
c4.metric("States", df['state'].nunique() if 'state' in df else 0)

# -------- Sidebar (no CSV upload)
with st.sidebar:
    st.header("Controls")
    mode = st.radio("Mode", ["Overview & Insights", "Single Predict"], index=0)
    st.markdown("---")

    # Show Outlier filters ONLY for Overview mode
    if mode == "Overview & Insights":
        st.subheader("Outlier filters")
        min_price = st.number_input(
            "Min price ($)", min_value=0, max_value=100_000, value=100, step=100,
            help="Hide unrealistically low prices below this value in charts.")
        max_price = st.number_input(
            "Max price ($)", min_value=1_000, max_value=1_000_000, value=200_000, step=1_000,
            help="Filter out extreme prices above this value in charts.")
        max_odo = st.number_input(
            "Max odometer (miles)", min_value=0, max_value=10_000_000, value=500_000, step=1_000,
            help="Filter out extreme mileages above this value in charts.")
    else:
        # Dummy values so variables exist (not used in Single Predict)
        min_price, max_price, max_odo = 0, 1_000_000, 10_000_000

    st.markdown("---")
    st.caption("Model: sklearn Pipeline (preprocessing + BaggingRegressor)")

# -------- Overview & Insights
if mode == "Overview & Insights":
    st.subheader("Distributions & Patterns")

    # === Big-data friendly switches ===
    with st.expander("Performance settings (for very large datasets)"):
        max_points = st.slider("Max points for scatter/box (sampling)", 5_000, 100_000, 25_000, 5_000,
                               help="Visuals subsample rows above this to keep the app snappy.")
        top_k = st.slider("Top K categories (manufacturer/model)", 5, 50, 15, 1,
                          help="Show only the most frequent categories to avoid clutter.")

    # Filters
    if 'year' in df and df['year'].notna().any():
        y0, y1 = int(df['year'].min()), int(df['year'].max())
    else:
        y0, y1 = 2000, 2025
    if 'price' in df and df['price'].notna().any():
        p0, p1 = int(df['price'].min()), int(df['price'].max())
    else:
        p0, p1 = 1000, 60000

    f1, f2, f3, f4 = st.columns([1, 1, 2, 2])
    with f1:
        year_range = st.slider("Year", y0, y1, (max(y0, 2005), y1))
    with f2:
        price_range = st.slider("Price ($)", p0, p1, (max(1000, p0), min(p1, 60000)), step=500)
    with f3:
        mfr_opts = sorted(df['manufacturer'].dropna().unique()) if 'manufacturer' in df else []
        sel_mfr = st.multiselect("Manufacturer", mfr_opts, default=mfr_opts[:6] if mfr_opts else [])
    with f4:
        st_opts = sorted(df['state'].dropna().unique()) if 'state' in df else []
        sel_state = st.multiselect("State", st_opts, default=st_opts[:10] if st_opts else [])

    # Apply filters (vectorized, minimal copies)
    dff = df
    if 'year' in dff:
        dff = dff[(dff['year'] >= year_range[0]) & (dff['year'] <= year_range[1])]
    if 'price' in dff:
        dff = dff[(dff['price'] >= price_range[0]) & (dff['price'] <= price_range[1])]
    if sel_mfr:
        dff = dff[dff['manufacturer'].isin(sel_mfr)]
    if sel_state:
        dff = dff[dff['state'].isin(sel_state)]
    # Outlier caps (now both lower & upper bounds for price)
    if 'price' in dff:
        dff = dff[(dff['price'] >= min_price) & (dff['price'] <= max_price)]
    if 'odometer' in dff:
        dff = dff[dff['odometer'] <= max_odo]
    if 'odometer' in dff:
        dff = dff[dff['odometer'] <= max_odo]

    # Guard: empty selection -> friendly message
    if dff is None or len(dff) == 0:
        st.warning("No rows match your filters. Clear a filter or widen the ranges.")
    
    # Tabs with richer visuals
    t1, t2, t3, t4, t5 = st.tabs([
        "Price & Year", "Heatmaps", "Odometer vs Price", "Segments", "By State"
    ])

    # --- t1: Price & Year distributions
    with t1:
        cols = st.columns(2)
        # Histogram of price (filtered snapshot)
        if 'price' in dff and len(dff) > 0:
            price_chart = (
                alt.Chart(dff)
                .transform_bin(["binned_price"], "price", bin=alt.Bin(maxbins=40))
                .transform_aggregate(count='count()', groupby=['binned_price'])
                .mark_bar(color='#1f6feb')
                .encode(x=alt.X('binned_price:Q', title='Price (USD)'), y='count:Q')
                .properties(height=280)
            )
            cols[0].altair_chart(price_chart, use_container_width=True)
        else:
            cols[0].info("No rows after filters.")
        # Yearly trend: always recompute from *filtered* data so caps apply
        if 'year' in dff and 'price' in dff and len(dff) > 0:
            tmp = dff.groupby('year', as_index=False)['price'].median()
            line = (
                alt.Chart(tmp)
                .mark_line(point=True, color='#0ea5e9')
                .encode(x=alt.X('year:Q'), y=alt.Y('price:Q', title='Median price (filtered & capped)'))
                .properties(height=280)
            )
            cols[1].altair_chart(line, use_container_width=True)
        else:
            cols[1].info("No data for yearly trend after filters.")

    # --- t2: Heatmaps (State choropleth + Price vs Year density)
    with t2:
        st.markdown("### Geographic & density heatmaps")
        cA, cB = st.columns([1,1])
        # Choropleth by state (median price)
        if 'state_price' in aggs and len(aggs['state_price']) > 0:
            sp = aggs['state_price'].dropna(subset=['state_code']).copy()
            lo = float(sp['median_price'].quantile(0.05))
            hi = float(sp['median_price'].quantile(0.95))
            fig_choro = px.choropleth(
                sp, locations='state_code', color='median_price', locationmode='USA-states', scope='usa',
                color_continuous_scale='Blues', range_color=(lo, hi), labels={'median_price':'Median Price ($)'}
            )
            fig_choro.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cA.plotly_chart(fig_choro, use_container_width=True)
            cA.caption("Using pre-aggregated state medians (full dataset). Filters above do not affect this map.")
        elif {'state','price'}.issubset(dff.columns) and len(dff) > 0:
            state_med = dff.groupby('state', as_index=False)['price'].median()
            state_med['state_code'] = state_med['state'].astype(str).str.upper()
            lo = float(state_med['price'].quantile(0.05))
            hi = float(state_med['price'].quantile(0.95))
            fig_choro = px.choropleth(
                state_med, locations='state_code', color='price', locationmode='USA-states', scope='usa',
                color_continuous_scale='Blues', range_color=(lo, hi), labels={'price':'Median Price ($)'}
            )
            fig_choro.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cA.plotly_chart(fig_choro, use_container_width=True)
        else:
            cA.info("Need non-empty 'state' and 'price' to draw the choropleth.")
        # Year vs Price density heatmap (filtered & capped)
        if {'price','year'}.issubset(dff.columns) and len(dff) > 0:
            fig_dens = px.density_heatmap(
                dff, x='year', y='price', nbinsx=40, nbinsy=40,
                color_continuous_scale='Blues',
                labels={'color':'Count'}
            )
            fig_dens.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cB.plotly_chart(fig_dens, use_container_width=True)
            cB.caption("Filtered & capped view â€” shows concentration of listings by year Ã— price.")
        else:
            cB.info("Need non-empty data to draw the heatmap.")

    # --- t3: Odometer vs Price scatter / hexbin
    with t3:
        st.markdown("#### Odometer analysis (filtered & capped)")
        if {'odometer','price'}.issubset(dff.columns):
            dplot = dff.dropna(subset=['odometer','price'])
            if len(dplot) > max_points:
                dplot = dplot.sample(max_points, random_state=0)
            fig = px.scatter(
                dplot, x='odometer', y='price', color='condition',
                hover_data=['manufacturer','type','year','state']
            )
            fig.update_layout(margin=dict(l=0, r=0, t=30, b=0), height=520)
            st.plotly_chart(fig, use_container_width=True)

            st.caption("Binned density:")
            fig_hex = px.density_heatmap(dff, x='odometer', y='price', nbinsx=40, nbinsy=40)
            fig_hex.update_layout(margin=dict(l=0, r=0, t=10, b=0), height=360)
            st.plotly_chart(fig_hex, use_container_width=True)
        else:
            st.info("Odometer/price not available in snapshot.")


    # --- t4: Segments (Treemap & Boxplot)
    with t4:
        cols = st.columns(2)
        # Treemap: Manufacturer â†’ Type (count)
        if 'mfr_type_freq' in aggs and len(aggs['mfr_type_freq']) > 0:
            freq = aggs['mfr_type_freq'].copy()
            freq_top = freq.groupby('manufacturer', group_keys=False).head(top_k)
            fig_tree = px.treemap(freq_top, path=['manufacturer','type'], values='size')
            fig_tree.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cols[0].plotly_chart(fig_tree, use_container_width=True)
            cols[0].caption("Using pre-aggregated counts (full dataset).")
        elif {'manufacturer','type'}.issubset(dff.columns):
            freq = dff.groupby(['manufacturer','type'], as_index=False).size()
            freq = freq.sort_values('size', ascending=False)
            freq_top = freq.groupby('manufacturer').head(top_k)
            fig_tree = px.treemap(freq_top, path=['manufacturer','type'], values='size')
            fig_tree.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cols[0].plotly_chart(fig_tree, use_container_width=True)
        # Box: price by type
        if {'type','price'}.issubset(dff.columns):
            dbox = dff
            if dbox['type'].nunique() > top_k:
                keep = dbox['type'].value_counts().head(top_k).index
                dbox = dbox[dbox['type'].isin(keep)]
            fig_box = px.box(dbox, x='type', y='price')
            fig_box.update_layout(margin=dict(l=0,r=0,t=30,b=0), height=420)
            cols[1].plotly_chart(fig_box, use_container_width=True)

    # --- t5: By State (table + bars)
    with t5:
        if 'state_price' in aggs and len(aggs['state_price']) > 0:
            agg = aggs['state_price'].copy()
            st.dataframe(agg[['state','listings','median_price','avg_price']].sort_values('median_price', ascending=False), use_container_width=True)
            st.altair_chart(
                alt.Chart(agg)
                .mark_bar(color='#1d4ed8')
                .encode(x=alt.X('state:N', sort='-y'), y=alt.Y('median_price:Q', title='Median price'))
                .properties(height=420),
                use_container_width=True
            )
            st.caption("Using pre-aggregated state metrics (full dataset).")
        elif {'state','price'}.issubset(dff.columns):
            agg = dff.groupby('state').agg(
                listings=('state','size'),
                median_price=('price','median'),
                avg_price=('price','mean')
            ).reset_index().sort_values('median_price', ascending=False)
            st.dataframe(agg, use_container_width=True)
            st.altair_chart(
                alt.Chart(agg)
                .mark_bar(color='#1d4ed8')
                .encode(x=alt.X('state:N', sort='-y'), y=alt.Y('median_price:Q', title='Median price'))
                .properties(height=420),
                use_container_width=True
            )
        else:
            st.info("State column not found in snapshot.")

# -------- Single Predict (uses your preloaded Pipeline)
else:
    st.subheader("Predict a resale price")

    def opts(col, fallback):
        return sorted(df[col].astype(str).unique()) if col in df else fallback

    c1, c2, c3 = st.columns(3)
    with c1:
        year = st.number_input("Year", min_value=1985, max_value=2025,
                               value=int(df['year'].median()) if 'year' in df else 2015)
        odometer = st.number_input("Odometer (miles)", min_value=0, max_value=500_000,
                                   value=int(df['odometer'].median()) if 'odometer' in df else 75000,
                                   step=500)
        condition = st.selectbox("Condition", opts('condition', ['excellent','good','fair','like new','salvage']))
    with c2:
        manufacturer = st.selectbox("Manufacturer", opts('manufacturer', ['toyota','honda','ford']))
        fuel = st.selectbox("Fuel", opts('fuel', ['gas','diesel','hybrid','electric']))
        transmission = st.selectbox("Transmission", opts('transmission', ['automatic','manual']))
    with c3:
        drive = st.selectbox("Drive", opts('drive', ['fwd','rwd','4wd']))
        vtype = st.selectbox("Type", opts('type', ['sedan','SUV','pickup','hatchback','wagon']))
        paint_color = st.selectbox("Paint Color", opts('paint_color', ['white','black','silver','gray','blue','red']))

    # default state from dataset mode if available
    state_val = df['state'].mode().iat[0] if 'state' in df and not df['state'].empty else 'ca'

    if st.button("Predict Price", type="primary"):
        if model is None:
            st.error("Trained pipeline not found. Please add models/final_pipeline.joblib.")
        else:
            raw_row = pd.DataFrame([{
                'year': year,
                'odometer': odometer,
                'manufacturer': str(manufacturer),
                'condition': str(condition),
                'cylinders': '4 cylinders',  # adjust if your training used a different default
                'fuel': str(fuel),
                'transmission': str(transmission),
                'drive': str(drive),
                'type': str(vtype),
                'paint_color': str(paint_color),
                'state': state_val,
            }])
            row = sanitize_inputs(raw_row)
            row = row[TRAIN_INPUT_COLS]
            yhat = float(model.predict(row)[0])
            lo, hi = max(1000, yhat * 0.9), yhat * 1.1

            k1, k2 = st.columns(2)
            k1.metric("Estimated Price", f"${yhat:,.0f}")
            k2.metric("~Â±10% range", f"${lo:,.0f} â€“ ${hi:,.0f}")

st.markdown("---")
st.caption("Preloaded BaggingRegressor pipeline + EDA snapshot. No uploads required.")
